{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import pykalman as pk\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path = \"./Data/SENSEX/<SYMBOL>.csv\"\n",
    "def error_percentage(value1, value2):\n",
    "    print \"the error in percentage is\" , (abs(value1 - value2) / value1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def symbol_to_path(symbol, base_dir = \"./Data/SENSEX\"):\n",
    "    \"\"\"Returns\n",
    "     CSV file path for given symbol \"\"\"\n",
    "    return os.path.join(base_dir, \"{}.csv\".format(str(symbol)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_frame(symbols, dates):\n",
    "\n",
    "    df = pd.DataFrame(index = dates)\n",
    "\n",
    "    #sensex file acts as base;  this is the index file for sensex\n",
    "    if 'SENSEX' not in symbols:\n",
    "        symbols.insert(0, 'SENSEX')\n",
    "\n",
    "    for symbol in  symbols:\n",
    "        df_temp = pd.read_csv(symbol_to_path(symbol),\n",
    "                               index_col = \"Date\", parse_dates = True,\n",
    "                               usecols = ['Date', 'Adj Close'],na_values = ['nan'])\n",
    "\n",
    "        df_temp = df_temp.rename(columns={'Adj Close' : symbol})\n",
    "        if symbol != 'SENSEX':\n",
    "            df = df.join(df_temp)\n",
    "        else:\n",
    "            df = df.join(df_temp, how = 'inner')\n",
    "        \"\"\"\n",
    "            This is important as SENSEX csv file is base for all stocks\n",
    "             we have an entry for this whenever SENSEX trades,\n",
    "             but for any compamy listed on sensex, it may not trade for all\n",
    "             days sensex has worked,, so we take a left join\n",
    "        \"\"\"\n",
    "        #using fillna() to fill missing values\n",
    "        #use ffill first to avoid peeping in future\n",
    "        #bfill is used if data is missing from beginning\n",
    "        df.fillna(method = \"ffill\", inplace = \"TRUE\")\n",
    "        df.fillna(method = \"bfill\", inplace = \"TRUE\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_data(df):\n",
    "    #normalize using first row of data\n",
    "    #observe use of row slicing\n",
    "    return df/df.ix[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_data(df, theTitle = \"Stock Prices\"):\n",
    "    \"\"\"plot stock prices \"\"\"\n",
    "    df = normalize_data(df)\n",
    "    ax = df.plot(title = theTitle)\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Price\")\n",
    "    #df[['ITC', 'TCS']].plot(title = theTitle)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_stats(df):\n",
    "    print \"the standard deviation is \\n\", df.std()\n",
    "    print \"the mean is\\n\", df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_bollinger_bands(df, length=30, numsd=2):\n",
    "    \"\"\" returns average, upper band, and lower band\n",
    "        there are three steps , find rolling mean, then rolling std deviation\n",
    "        then find upper and lower bands\n",
    "    \"\"\"\n",
    "    rm = pd.stats.moments.rolling_mean(df,length)\n",
    "    rmstd = pd.stats.moments.rolling_std(df,length)\n",
    "    upperband = rm + (rmstd*numsd)\n",
    "    lowerband = rm - (rmstd*numsd)\n",
    "    #plotting these stats\n",
    "    ax  = df['TCS'].plot(title = \"Bollinger Bands\", label = \"TCS\")\n",
    "    rm.plot(label = \"Rolling mean\", ax = ax)\n",
    "    upperband.plot(label='upper band', ax = ax)\n",
    "    lowerband.plot(label = 'lower band ', ax = ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_daily_returns(df):\n",
    "    daily = df.copy()\n",
    "    daily[1:] = (df[1:] / df[:-1].values) - 1\n",
    "    #hey using values only for second is necessary bcoz\n",
    "    # else it will do index wise stuff, so our goal os shifting\n",
    "    #by 1 and dividing is destroyed,\n",
    "    daily.ix[0, :] = 0\n",
    "    print \"the cumulative returns \\n\", daily.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sentimentstemp(df):\n",
    "    in_sample = df['2014-05-13']\n",
    "    #here the data frame has 3 columns SENSEX, TCS, ITC\n",
    "    #lets first predict for SENSEX\n",
    "    print \"the values on date 2014-05-13 is \" , in_sample['SENSEX']\n",
    "\n",
    "    # hey now i need to make a vector to store the polarity\n",
    "    # hey i may need to store in a matrix,, \n",
    "    \n",
    "    dates = [\"2014-05-13.txt\", \"2014-05-14.txt\"]\n",
    "    sentiments = []\n",
    "    for date in dates:\n",
    "        lines = [line.rstrip('\\n') for line in open('./Data/TwitterScraps/' + date)]\n",
    "        #lines is a vector of these lines\n",
    "        #sentiMatrix = TextBlob(lines[:]) hey textblob accepts a string not a list\n",
    "        sumSentiment = 0\n",
    "        for l in lines:\n",
    "            sumSentiment += TextBlob(l).sentiment.polarity\n",
    "        \n",
    "        sentiments.append(sumSentiment/float(len(lines)))\n",
    "\n",
    "    #print \"hey the sentiments are\" , sentiments\n",
    "    temp = df['2014-05-13']['SENSEX']\n",
    "    print \"hey temp is \" , temp\n",
    "    return sentiments[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sentiments():\n",
    "    start_date = \"2014-05-07\"\n",
    "    end_date = \"2014-05-16\"\n",
    "    # hey we will make a pandas data frame;; indexed by dates like we have created earlier\n",
    "    # this data frame will store sentiments for different dates\n",
    "    \n",
    "    dates = pd.date_range(start_date, end_date)\n",
    "    sentiments = pd.DataFrame(index = dates)\n",
    "    d1 = dt.datetime(2014, 05, 07, 0, 0)\n",
    "    d2 = dt.datetime(2014, 05, 16, 0, 0)\n",
    "\n",
    "    delta = d2 - d1\n",
    "    \n",
    "    dateList = []\n",
    "    for i in range(delta.days + 1):\n",
    "        dateObject = d1 + dt.timedelta(days=i)\n",
    "        dateList.append(dateObject.strftime('%Y-%m-%d'))\n",
    "        \n",
    "    for date in dateList:\n",
    "        lines = [line.rstrip('\\n') for line in open('./Data/TwitterScraps/' + date + '.txt')]\n",
    "        #lines is a vector of these lines\n",
    "        #sentiMatrix = TextBlob(lines[:]) hey textblob accepts a string not a list\n",
    "        sumSentiment = 0\n",
    "        for l in lines:\n",
    "            sumSentiment += TextBlob(l).sentiment.polarity\n",
    "        if date != start_date:\n",
    "            sentiments[date] = ( (sumSentiment/float(len(lines))) + sentiments[date - datetime.timedelta(days=1)])\n",
    "        else:\n",
    "            sentiments[date] = (sumSentiment/float(len(lines)))    \n",
    "        return sentiments\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kalman_filtertemp(df, sentiMatrix):\n",
    "    #creating a kalman filter object,,  \n",
    "    \n",
    "    #hey problem ,, df dimension not equal to sentiMatrix as twitter sentiment analysis daily,, but \n",
    "    #stock market does not open everyday, so we need to do something,, \n",
    "    \n",
    "   \n",
    "    \n",
    "    obs_mat = np.vstack([df['2014-05-13']['SENSEX'], sentiMatrix[0:1]]).T[:, np.newaxis]\n",
    "    #obs_mat = np.vstack([df['SENSEX'], sentiMatrix]).T[:, np.newaxis]\n",
    "    #obs_mat = np.vstack([df['SENSEX'], sentiMatrix]).T[:, np.newaxis]\n",
    "    \n",
    "    #obs_mat = np.vstack([sentiMatrix, np.ones(1)]).T[:, np.newaxis]\n",
    "    \n",
    "    \n",
    "    delta = 1e-5\n",
    "    trans_cov = delta / (1 - delta) * np.eye(2)\n",
    "\n",
    "    kf = pk.KalmanFilter(n_dim_obs=1, n_dim_state=2,\n",
    "                  initial_state_mean=np.zeros(2),\n",
    "                  initial_state_covariance=np.ones((2, 2)),\n",
    "                  transition_matrices=np.eye(2),\n",
    "                  observation_matrices=obs_mat,\n",
    "                  observation_covariance=1.0,\n",
    "                  transition_covariance=trans_cov)\n",
    "    \n",
    "    \n",
    "    state_means, state_covs = kf.filter([df['2014-05-13']['SENSEX']])\n",
    "    \n",
    "    value1 = df['2014-05-14']['SENSEX']\n",
    "    print \"the price on day \" , value1\n",
    "\n",
    "    myvalue = df['2014-05-13']['SENSEX']\n",
    "    value2 = myvalue*state_means[0][0]\n",
    "    print \"the price on day 2014-05-14 as predicted by noise and price of \" , value2\n",
    "     #print \"state_covs is \", state_covs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kalman_filter(df, sentiMatrix):\n",
    "    #creating a kalman filter object,,  \n",
    "    \n",
    "    #hey problem ,, df dimension not equal to sentiMatrix as twitter sentiment analysis daily,, but \n",
    "    #stock market does not open everyday, so we need to do something,, \n",
    "    \n",
    "    start_date = \"2014-05-07\"\n",
    "    end_date = \"2014-05-16\"\n",
    "\n",
    "    # i will first retrieve all indexes from pandas dataframe\n",
    "    \n",
    "    dates = pd.date_range(start_date, end_date)\n",
    "    adj_close_df = pd.DataFrame(index = dates)\n",
    "    adj_close_df = adj_close_df.join(df['SENSEX'], how = \"inner\")\n",
    "   \n",
    "    # this step is necessary as the dates are in reverse order in df which is supplied as arg\n",
    "    adj_close_df = adj_close_df.sort_index(ascending=True, axis=0)\n",
    "    print \"The new adjusted close  data frame is \", adj_close_df\n",
    "\n",
    "    index_List = adj_close_df.index.tolist()\n",
    "    sentiment_df = pd.DataFrame(index = index_List)\n",
    "    sentiment_df = sentiment_df.join(sentiMatrix)\n",
    "    \n",
    "    obs_mat = np.vstack([adj_close_df['SENSEX'], sentiment_df]).T[:, np.newaxis]\n",
    "    #obs_mat = np.vstack([sentiMatrix, np.ones(1)]).T[:, np.newaxis]\n",
    "    \n",
    "    delta = 1e-5\n",
    "    trans_cov = delta / (1 - delta) * np.eye(2)\n",
    "    \n",
    "    # it is the fastest way,, better than len() or count()\n",
    "    num_of_obs = adj_close_df.shape[0]\n",
    "    print num_obs\n",
    "    kf = pk.KalmanFilter(n_dim_obs=num_obs, n_dim_state=2,\n",
    "                  initial_state_mean=np.zeros(8),\n",
    "                  initial_state_covariance=np.ones((8, 8)),\n",
    "                  transition_matrices=np.eye(8),\n",
    "                  observation_matrices=obs_mat,\n",
    "                  observation_covariance=1.0,\n",
    "                  transition_covariance=trans_cov)\n",
    "    \n",
    "    \n",
    "    state_means, state_covs = kf.filter([df['SENSEX']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_run():\n",
    "\n",
    "    start_date = '2014-01-01'\n",
    "    end_date = '2016-10-07'\n",
    "    dates = pd.date_range(start_date, end_date)\n",
    "    symbols = ['SENSEX']\n",
    "    df = get_data_frame(symbols, dates)\n",
    "    #plot_data(df)\n",
    "    #compute_bollinger_bands(df, 20, 2)\n",
    "    #compute_daily_returns(df)\n",
    "    \n",
    "    #intially sentiMatrix has only one value,, \n",
    "    sentiMatrix = get_sentiments()\n",
    "    \n",
    "    #print sentiMatrix.shape\n",
    "    \n",
    "    \n",
    "    \n",
    "    #hey problem is i have sentiment analysis of all days\n",
    "    # the stock market does not open everyday;; lets implement an inner join,,\n",
    "    \n",
    "    kalman_filter(df, sentiMatrix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new adjusted close  data frame is                    SENSEX\n",
      "2014-05-07  22323.900391\n",
      "2014-05-08  22344.039062\n",
      "2014-05-09  22994.230469\n",
      "2014-05-12  23551.000000\n",
      "2014-05-13  23871.230469\n",
      "2014-05-14  23815.119141\n",
      "2014-05-15  23905.599609\n",
      "2014-05-16  24121.740234\n",
      "The sentiment data frame is              2014-05-07\n",
      "2014-05-07   -0.013472\n",
      "2014-05-08   -0.013472\n",
      "2014-05-09   -0.013472\n",
      "2014-05-12   -0.013472\n",
      "2014-05-13   -0.013472\n",
      "2014-05-14   -0.013472\n",
      "2014-05-15   -0.013472\n",
      "2014-05-16   -0.013472\n",
      "the shape of adjusted close dataframe is  (8, 1)\n",
      "The shape of sentiment data frame is  (8, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-178-65ef9e9fca61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtest_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-177-a3a352142489>\u001b[0m in \u001b[0;36mtest_run\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# the stock market does not open everyday;; lets implement an inner join,,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mkalman_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiMatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-176-35d79bbdc621>\u001b[0m in \u001b[0;36mkalman_filter\u001b[0;34m(df, sentiMatrix)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m#obs_mat = np.vstack([df['SENSEX'], sentiMatrix]).T[:, np.newaxis]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mobs_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madj_close_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SENSEX'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiment_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m#obs_mat = np.vstack([sentiMatrix, np.ones(1)]).T[:, np.newaxis]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/core/shape_base.pyc\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \"\"\"\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
